"""
–û–ø–∏—Å–∞–Ω–∏–µ:
–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –æ–¥–µ–∂–¥—ã –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LangChain + ChromaDB.

–í—ã–±–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è HuggingFaceEmbedding c –º–æ–¥–µ–ª—å—é `all-MiniLM-L6-v2` –∫–∞–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–æ/—Å–∫–æ—Ä–æ—Å—Ç—å/–≤–µ—Å. –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –ø–∞—Ä–∞—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è fashion-–æ–ø–∏—Å–∞–Ω–∏–π.
"""
import logging

from chromadb import PersistentClient
from langchain.schema import Document

from typing import List, Dict
import os

from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

from database.sqlite_init import get_user_clothes

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
VECTOR_DB_DIR = "lang_models/chroma_store"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def build_vector_store(user_id: int) -> None:
    """
    –°–æ–∑–¥–∞—ë—Ç Chroma-–±–∞–∑—É —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –¥–ª—è –≥–∞—Ä–¥–µ—Ä–æ–±–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —é–∑–µ—Ä–∞.
    –î–∞–Ω–Ω—ã–µ –±–µ—Ä—É—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –∏–∑ SQLite.
    """
    rows = get_user_clothes(user_id)

    documents = []
    for filename, description, season, sex, _ in rows:
        logging.info(f'–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ñ–∞–π–ª: {filename}, —Å–µ–∑–æ–Ω: {season}, –ø–æ–ª: {sex}')
        doc = Document(
            page_content=description,
            metadata={
                "filename": filename,
                "season": season,
                "sex": sex
            }
        )
        documents.append(doc)

    user_path = os.path.join(VECTOR_DB_DIR, str(user_id))
    os.makedirs(user_path, exist_ok=True)

    Chroma.from_documents(
        documents=documents,
        embedding=embedding_model,
        persist_directory=user_path
    ).persist()


def search_similar_items(user_id: int, prompt: str, top_k: int = 5) -> List[Dict]:
    """
    –ò—â–µ—Ç —Å—Ö–æ–∂–∏–µ –≤–µ—â–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ dict —Å filename + score
    """
    user_path = os.path.join(VECTOR_DB_DIR, str(user_id))
    if not os.path.exists(user_path):
        raise ValueError("–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞ ")

    vectorstore = Chroma(
        persist_directory=user_path,
        embedding_function=embedding_model
    )

    results = vectorstore.similarity_search_with_score(prompt, k=top_k)

    return [
        {
            "filename": doc.metadata["filename"],
            "score": score
        }
        for doc, score in results
    ]


def inspect_chroma_db(collection_name: str = "clothes"):
    client = PersistentClient(path=f"storage/chroma_{collection_name}")
    collection = client.get_or_create_collection(name=collection_name)

    print(f"\nüìä Documents in ChromaDB Collection '{collection_name}':")
    items = collection.get()
    for idx, doc_id in enumerate(items.get("ids", [])):
        print(f"\nüîπ ID: {doc_id}")
        print(f"Metadata: {items.get('metadatas', [])[idx]}")
        print(f"Document Text: {items.get('documents', [])[idx]}")
